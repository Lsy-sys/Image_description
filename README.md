# æœé¥°å›¾åƒæè¿°ç”Ÿæˆé¡¹ç›®

åŸºäºæ·±åº¦å­¦ä¹ çš„æœé¥°å›¾åƒè‡ªåŠ¨æè¿°ç”Ÿæˆç³»ç»Ÿï¼Œä½¿ç”¨CNN+GRUå’ŒTransformeræ¶æ„å®ç°å›¾åƒåˆ°æ–‡æœ¬çš„è½¬æ¢ã€‚

## ğŸ¯ é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®å®ç°äº†ä¸¤ç§ä¸»æµçš„å›¾åƒæè¿°ç”Ÿæˆæ¨¡å‹ï¼š
1. **CNN+GRUæ¨¡å‹**: ä½¿ç”¨ResNet-50æå–å›¾åƒç‰¹å¾ï¼ŒGRUç”Ÿæˆæ–‡æœ¬æè¿°
2. **åŒºåŸŸç‰¹å¾+Transformeræ¨¡å‹**: ä½¿ç”¨Faster R-CNNæå–åŒºåŸŸç‰¹å¾ï¼ŒTransformerè¿›è¡Œåºåˆ—å»ºæ¨¡

### ä¸»è¦åŠŸèƒ½
- ğŸ–¼ï¸ **å›¾åƒç†è§£**: è‡ªåŠ¨åˆ†ææœé¥°å›¾åƒä¸­çš„é¢œè‰²ã€æ¬¾å¼ã€æè´¨ç­‰ç‰¹å¾
- ğŸ“ **æ–‡æœ¬ç”Ÿæˆ**: ç”Ÿæˆè‡ªç„¶ã€å‡†ç¡®çš„æœé¥°æè¿°æ–‡æœ¬
- ğŸ”„ **å¤šæ¨¡å‹æ”¯æŒ**: æä¾›å¤šç§æ¨¡å‹æ¶æ„é€‰æ‹©
- ğŸ“Š **æ€§èƒ½è¯„ä¼°**: ä½¿ç”¨ROUGE-Lå’ŒCIDEr-DæŒ‡æ ‡è¯„ä¼°ç”Ÿæˆè´¨é‡

## ğŸ“ é¡¹ç›®ç»“æ„

```
codes/
â”œâ”€â”€ data/                    # æ•°æ®å¤„ç†æ¨¡å—
â”‚   â”œâ”€â”€ dataset.py          # DeepFashionæ•°æ®é›†åŠ è½½å™¨
â”‚   â”œâ”€â”€ transforms.py       # å›¾åƒé¢„å¤„ç†å’Œå¢å¼º
â”‚   â”œâ”€â”€ vocabulary.py       # è¯æ±‡è¡¨æ„å»ºå’Œç®¡ç†
â”‚   â””â”€â”€ utils.py           # æ•°æ®å·¥å…·å‡½æ•°
â”œâ”€â”€ models/                 # æ¨¡å‹å®šä¹‰
â”‚   â”œâ”€â”€ cnn_gru/           # CNN+GRUæ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ encoder.py     # ResNet-50å›¾åƒç¼–ç å™¨
â”‚   â”‚   â”œâ”€â”€ decoder.py     # GRUæ–‡æœ¬è§£ç å™¨
â”‚   â”‚   â””â”€â”€ model.py       # å®Œæ•´CNN+GRUæ¨¡å‹
â”‚   â””â”€â”€ transformer/       # Transformeræ¨¡å‹
â”‚       â”œâ”€â”€ encoder.py     # Transformerç¼–ç å™¨
â”‚       â”œâ”€â”€ decoder.py     # Transformerè§£ç å™¨
â”‚       â”œâ”€â”€ attention.py   # å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶
â”‚       â””â”€â”€ model.py       # å®Œæ•´Transformeræ¨¡å‹
â”œâ”€â”€ evaluation/            # è¯„æµ‹æŒ‡æ ‡
â”‚   â”œâ”€â”€ rouge_l.py        # ROUGE-Lè¯„æµ‹æŒ‡æ ‡
â”‚   â””â”€â”€ cider_d.py        # CIDEr-Dè¯„æµ‹æŒ‡æ ‡
â”œâ”€â”€ training/              # è®­ç»ƒæ¨¡å—
â”‚   â””â”€â”€ trainer.py        # è®­ç»ƒå™¨åŸºç±»
â”œâ”€â”€ configs/               # é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ cnn_gru_config.yaml      # CNN+GRUæ¨¡å‹é…ç½®
â”‚   â””â”€â”€ transformer_config.yaml  # Transformeræ¨¡å‹é…ç½®
â”œâ”€â”€ scripts/               # è¿è¡Œè„šæœ¬
â”‚   â”œâ”€â”€ simple_train.py    # ç®€åŒ–è®­ç»ƒè„šæœ¬
â”‚   â”œâ”€â”€ train_cnn_gru.py   # CNN+GRUè®­ç»ƒè„šæœ¬
â”‚   â””â”€â”€ evaluate.py        # æ¨¡å‹è¯„ä¼°è„šæœ¬
â”œâ”€â”€ checkpoints/           # æ¨¡å‹æ£€æŸ¥ç‚¹
â”œâ”€â”€ logs/                  # è®­ç»ƒæ—¥å¿—
â””â”€â”€ requirements.txt       # ä¾èµ–åŒ…åˆ—è¡¨
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

```bash
# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# ç¡®ä¿CUDAå¯ç”¨ï¼ˆå¯é€‰ï¼Œç”¨äºGPUåŠ é€Ÿï¼‰
python -c "import torch; print('CUDA available:', torch.cuda.is_available())"
```

### 2. æ•°æ®å‡†å¤‡

é¡¹ç›®ä½¿ç”¨DeepFashion-MultiModalæ•°æ®é›†ï¼ŒåŒ…å«ï¼š
- **å›¾åƒæ•°æ®**: 44,096å¼ æœé¥°å›¾åƒ
- **æ–‡æœ¬æè¿°**: æ¯ä¸ªå›¾åƒå¯¹åº”å¤šä¸ªè‡ªç„¶è¯­è¨€æè¿°
- **æ•°æ®åˆ†å‰²**: è®­ç»ƒé›†(29,780) + éªŒè¯é›†(6,381) + æµ‹è¯•é›†(8,000)

#### æ•°æ®è·å–æ–¹å¼

ç”±äºæ•°æ®é›†å›¾ç‰‡æ–‡ä»¶è¾ƒå¤§ï¼Œå›¾ç‰‡æ–‡ä»¶ä¸ä¼šåŒ…å«åœ¨Gitä»“åº“ä¸­ã€‚è¯·æŒ‰ä»¥ä¸‹æ–¹å¼è·å–ï¼š

1. **ä¸‹è½½DeepFashion-MultiModalæ•°æ®é›†**åˆ° `data/DeepFashion-MultiModal/` ç›®å½•
2. **ç¡®ä¿ç›®å½•ç»“æ„å¦‚ä¸‹**ï¼š
```
data/DeepFashion-MultiModal/
â”œâ”€â”€ images/           # æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶ï¼ˆéœ€è¦ä¸‹è½½ï¼‰
â”œâ”€â”€ captions/         # æ‰€æœ‰æ ‡æ³¨æ–‡ä»¶ï¼ˆéœ€è¦ä¸‹è½½ï¼‰
â”œâ”€â”€ train_list.txt    # è®­ç»ƒé›†åˆ—è¡¨
â”œâ”€â”€ val_list.txt      # éªŒè¯é›†åˆ—è¡¨
â””â”€â”€ test_list.txt     # æµ‹è¯•é›†åˆ—è¡¨
```

3. **ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹**åˆ° `checkpoints/cnn_gru/best_model.pth`ï¼ˆå¯é€‰ï¼Œç”¨äºå¿«é€Ÿæµ‹è¯•ï¼‰

### 3. æ¨¡å‹è®­ç»ƒ

#### CNN+GRUæ¨¡å‹è®­ç»ƒ
```bash
# åŸºç¡€è®­ç»ƒ
python scripts/simple_train.py --config configs/cnn_gru_config.yaml --batch_size 16

# è‡ªå®šä¹‰å‚æ•°è®­ç»ƒ
python scripts/simple_train.py \
    --config configs/cnn_gru_config.yaml \
    --batch_size 32 \
    --epochs 100 \
    --learning_rate 0.0001
```

#### è®­ç»ƒå‚æ•°è¯´æ˜
- `--config`: é…ç½®æ–‡ä»¶è·¯å¾„
- `--batch_size`: æ‰¹æ¬¡å¤§å°ï¼ˆå»ºè®®GPU: 16-32, CPU: 8-16ï¼‰
- `--epochs`: è®­ç»ƒè½®æ•°ï¼ˆé»˜è®¤50ï¼‰
- `--learning_rate`: å­¦ä¹ ç‡ï¼ˆé»˜è®¤0.001ï¼‰

### 4. æ¨¡å‹æ¨ç†

è®­ç»ƒå®Œæˆåï¼Œæ¨¡å‹ä¼šä¿å­˜åœ¨ `checkpoints/cnn_gru/best_model.pth`ã€‚

#### æ–¹æ³•1: å‘½ä»¤è¡Œæ¨ç† (æ¨è)

```bash
# åŸºç¡€ä½¿ç”¨
python scripts/inference.py --image path/to/your/image.jpg

# æŒ‡å®šæ¨¡å‹è·¯å¾„
python scripts/inference.py --image path/to/your/image.jpg --model checkpoints/cnn_gru/best_model.pth

# è‡ªå®šä¹‰å‚æ•°
python scripts/inference.py \
    --image path/to/your/image.jpg \
    --model checkpoints/cnn_gru/best_model.pth \
    --max_length 30 \
    --device cuda
```

#### æ–¹æ³•2: Pythonä»£ç ä½¿ç”¨

```python
# ä½¿ç”¨æ¼”ç¤ºè„šæœ¬
python scripts/demo.py

# æˆ–åœ¨ä»£ç ä¸­ç›´æ¥ä½¿ç”¨
import torch
from models.cnn_gru.model import CNNGruModel
from data.transforms import ImageTransforms
from PIL import Image

# åŠ è½½æ¨¡å‹
checkpoint = torch.load('checkpoints/cnn_gru/best_model.pth')
vocab = checkpoint['vocab']

model = CNNGruModel(
    embed_size=512,
    hidden_size=512,
    vocab_size=len(vocab),
    num_layers=1,
    pretrained=True
)
model.load_state_dict(checkpoint['model_state_dict'])
model.eval()

# å›¾åƒé¢„å¤„ç†
transform = ImageTransforms(224, is_training=False)
image = Image.open('path/to/image.jpg').convert('RGB')
image_tensor = transform.get_transforms()(image).unsqueeze(0)

# ç”Ÿæˆæè¿°
def generate_caption(image_tensor, model, vocab, max_length=20):
    with torch.no_grad():
        # æå–å›¾åƒç‰¹å¾
        features = model.encoder(image_tensor)
        
        # ç”Ÿæˆæ–‡æœ¬
        caption = []
        hidden = model.decoder.init_hidden(1)
        
        for _ in range(max_length):
            output, hidden = model.decoder(features, hidden)
            word_id = output.argmax(1)
            
            if word_id.item() == vocab.word2idx['<eos>']:
                break
                
            word = vocab.idx2word[word_id.item()]
            if word not in ['<bos>', '<pad>', '<unk>']:
                caption.append(word)
        
        return ' '.join(caption)

# ç”Ÿæˆæè¿°
description = generate_caption(image_tensor, model, vocab)
print(f"ç”Ÿæˆçš„æè¿°: {description}")
```

#### æ–¹æ³•3: Jupyter Notebookä½¿ç”¨

```bash
# å¯åŠ¨Jupyter Notebook
jupyter notebook notebooks/image_caption_demo.ipynb
```

#### æ–¹æ³•4: æ‰¹é‡å¤„ç†

```python
from scripts.demo import ImageCaptionGenerator

# åˆ›å»ºæè¿°ç”Ÿæˆå™¨
generator = ImageCaptionGenerator('checkpoints/cnn_gru/best_model.pth')

# å•å¼ å›¾åƒ
caption = generator.generate_caption('path/to/image.jpg')
print(f"æè¿°: {caption}")

# æ‰¹é‡å¤„ç†
image_paths = ['image1.jpg', 'image2.jpg', 'image3.jpg']
results = generator.batch_generate(image_paths)
for path, caption in results.items():
    print(f"{path}: {caption}")
```

## ğŸ”§ æ¨¡å‹æ¶æ„è¯¦è§£

### CNN+GRUæ¨¡å‹
- **ç¼–ç å™¨**: ResNet-50é¢„è®­ç»ƒæ¨¡å‹ï¼Œæå–å›¾åƒå…¨å±€ç‰¹å¾
- **è§£ç å™¨**: å•å±‚GRUï¼ŒåŸºäºå›¾åƒç‰¹å¾ç”Ÿæˆæ–‡æœ¬åºåˆ—
- **æ³¨æ„åŠ›**: ç®€å•çš„ç‰¹å¾æ˜ å°„ï¼Œæ— å¤æ‚æ³¨æ„åŠ›æœºåˆ¶
- **é€‚ç”¨åœºæ™¯**: å¿«é€Ÿè®­ç»ƒï¼ŒåŸºç¡€æ€§èƒ½

### Transformeræ¨¡å‹
- **ç¼–ç å™¨**: å¤šå±‚Transformerç¼–ç å™¨ï¼Œå¤„ç†åŒºåŸŸç‰¹å¾
- **è§£ç å™¨**: å¤šå±‚Transformerè§£ç å™¨ï¼Œå¸¦è‡ªæ³¨æ„åŠ›æœºåˆ¶
- **æ³¨æ„åŠ›**: å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ï¼Œæ›´å¥½çš„ç‰¹å¾èåˆ
- **é€‚ç”¨åœºæ™¯**: é«˜è´¨é‡ç”Ÿæˆï¼Œå¤æ‚åœºæ™¯ç†è§£

## ğŸ“Š æ€§èƒ½è¯„ä¼°

### è¯„æµ‹æŒ‡æ ‡
- **ROUGE-L**: åŸºäºæœ€é•¿å…¬å…±å­åºåˆ—ï¼Œè¯„ä¼°ç”Ÿæˆæ–‡æœ¬çš„æµç•…æ€§
- **CIDEr-D**: åŸºäºTF-IDFçš„n-gramç›¸ä¼¼åº¦ï¼Œè¯„ä¼°æè¿°çš„å‡†ç¡®æ€§

### è¿è¡Œè¯„ä¼°
```bash
python scripts/evaluate.py \
    --model_path checkpoints/cnn_gru/best_model.pth \
    --test_data data/DeepFashion-MultiModal/test_list.txt
```

## âš™ï¸ é…ç½®è¯´æ˜

### CNN+GRUé…ç½® (configs/cnn_gru_config.yaml)
```yaml
model:
  embed_size: 512        # åµŒå…¥ç»´åº¦
  hidden_size: 512       # GRUéšè—å±‚å¤§å°
  vocab_size: 10000      # è¯æ±‡è¡¨å¤§å°
  num_layers: 1          # GRUå±‚æ•°
  dropout: 0.5           # Dropoutç‡

training:
  epochs: 50             # è®­ç»ƒè½®æ•°
  batch_size: 32         # æ‰¹æ¬¡å¤§å°
  learning_rate: 0.001   # å­¦ä¹ ç‡
  optimizer: 'adam'      # ä¼˜åŒ–å™¨
  grad_clip: 5.0         # æ¢¯åº¦è£å‰ª

data:
  image_size: 224        # å›¾åƒå°ºå¯¸
  max_caption_length: 20 # æœ€å¤§æè¿°é•¿åº¦
  min_freq: 5            # æœ€å°è¯é¢‘
```

## ğŸ¨ ä½¿ç”¨ç¤ºä¾‹

### è¾“å…¥å›¾åƒ
![ç¤ºä¾‹æœé¥°å›¾åƒ](ç¤ºä¾‹å›¾åƒè·¯å¾„)

### ç”Ÿæˆæè¿°
- **CNN+GRU**: "A woman wearing a blue dress with floral patterns"
- **Transformer**: "The woman is wearing a sleeveless blue dress with white floral patterns, perfect for summer occasions"

## ğŸ” é¡¹ç›®ç‰¹è‰²

1. **æ¨¡å—åŒ–è®¾è®¡**: æ¸…æ™°çš„ä»£ç ç»“æ„ï¼Œæ˜“äºæ‰©å±•å’Œç»´æŠ¤
2. **å¤šæ¨¡å‹æ”¯æŒ**: æä¾›å¤šç§æ¨¡å‹æ¶æ„é€‰æ‹©
3. **å®Œæ•´æµç¨‹**: ä»æ•°æ®é¢„å¤„ç†åˆ°æ¨¡å‹è®­ç»ƒå†åˆ°æ¨ç†è¯„ä¼°
4. **å¯é…ç½®æ€§**: ä¸°å¯Œçš„é…ç½®é€‰é¡¹ï¼Œæ”¯æŒä¸åŒå®éªŒéœ€æ±‚
5. **æ€§èƒ½ä¼˜åŒ–**: æ”¯æŒGPUåŠ é€Ÿï¼Œæä¾›è®­ç»ƒå’Œæ¨ç†ä¼˜åŒ–

## ğŸ“ æ³¨æ„äº‹é¡¹

1. **æ•°æ®è·¯å¾„**: ç¡®ä¿æ•°æ®æ–‡ä»¶è·¯å¾„æ­£ç¡®
2. **å†…å­˜éœ€æ±‚**: å»ºè®®è‡³å°‘8GBå†…å­˜ï¼Œæ¨è16GBä»¥ä¸Š
3. **GPUæ¨è**: ä½¿ç”¨GPUå¯æ˜¾è‘—åŠ é€Ÿè®­ç»ƒè¿‡ç¨‹
4. **æ¨¡å‹ä¿å­˜**: è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šè‡ªåŠ¨ä¿å­˜æœ€ä½³æ¨¡å‹å’Œæ£€æŸ¥ç‚¹


